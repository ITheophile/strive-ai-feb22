{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Transfer Learning\n\nIn this notebook, you'll learn how to use pre-trained networks to solved challenging problems in computer vision using the cat vs dog of yesterday.\n\nTransfer Learning consists of using, for the feature extraction part, the weights of a model that has been already trained on another dataset. \n\nOnce trained, these models work astonishingly well as feature detectors for images they weren't trained on. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n\nWith `torchvision.models` you can download these pre-trained networks and use them in your applications. We'll include `models` in our imports now.","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\nimport os\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:55:42.549922Z","iopub.execute_input":"2022-06-13T12:55:42.550374Z","iopub.status.idle":"2022-06-13T12:55:45.078935Z","shell.execute_reply.started":"2022-06-13T12:55:42.550343Z","shell.execute_reply":"2022-06-13T12:55:45.077734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the pretrained models require the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are `[0.485, 0.456, 0.406]` and the standard deviations are `[0.229, 0.224, 0.225]`.\n\n>**Bonus Exercise**: Try this at the end: build a data augmentation pipeline using Albumentations library (check the other notebook).","metadata":{}},{"cell_type":"code","source":"!wget https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n!unzip Cat_Dog_data.zip","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:56:17.094826Z","iopub.execute_input":"2022-06-13T12:56:17.095243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:43:36.932086Z","iopub.execute_input":"2022-06-13T12:43:36.932606Z","iopub.status.idle":"2022-06-13T12:43:47.495425Z","shell.execute_reply.started":"2022-06-13T12:43:36.932562Z","shell.execute_reply":"2022-06-13T12:43:47.494313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Load and preprocess the Cat vs Dog dataset of yesterday. \n## The images should have size 224x224\n\ndata_dir = './Cat_Dog_data'\n\n# TODO: Define transforms for the training data and testing data\ntrain_transforms = transforms.Compose([\n                                        transforms.Resize((224, 224)),\n                                        transforms.RandomRotation(30),\n                                        transforms.RandomHorizontalFlip(),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                                        ])\n\ntest_tranforms = transforms.Compose([\n                                        transforms.Resize((224, 224)),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                                        ])\n\n\n# Pass transforms in here, then run the next cell to see how the transforms look\ntrain_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform= train_transforms)\ntest_data = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform= test_tranforms)\n\ntrainloader = DataLoader(train_data, batch_size= 64, shuffle=True)\ntestloader = DataLoader(test_data, batch_size= 64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:58:59.452044Z","iopub.execute_input":"2022-06-13T12:58:59.452570Z","iopub.status.idle":"2022-06-13T12:58:59.590058Z","shell.execute_reply.started":"2022-06-13T12:58:59.452524Z","shell.execute_reply":"2022-06-13T12:58:59.588904Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"We can load in a model such as [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5). Let's print out the model architecture so we can see what's going on. You can pick other models as well from here: https://pytorch.org/docs/0.3.0/torchvision/models.html#id5","metadata":{}},{"cell_type":"code","source":"dir(models)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:47:39.070337Z","iopub.execute_input":"2022-06-13T12:47:39.07116Z","iopub.status.idle":"2022-06-13T12:47:39.079877Z","shell.execute_reply.started":"2022-06-13T12:47:39.071113Z","shell.execute_reply":"2022-06-13T12:47:39.079061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\nmodel","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-13T12:59:05.326223Z","iopub.execute_input":"2022-06-13T12:59:05.326694Z","iopub.status.idle":"2022-06-13T12:59:06.888939Z","shell.execute_reply.started":"2022-06-13T12:59:05.326662Z","shell.execute_reply":"2022-06-13T12:59:06.887738Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means **we need to replace the classifier, but the features will work perfectly on their own**. *In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers.*\n\n","metadata":{}},{"cell_type":"code","source":"model.fc.in_features","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:49:37.037286Z","iopub.execute_input":"2022-06-13T12:49:37.037738Z","iopub.status.idle":"2022-06-13T12:49:37.044198Z","shell.execute_reply.started":"2022-06-13T12:49:37.037699Z","shell.execute_reply":"2022-06-13T12:49:37.043293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False\n\nfrom collections import OrderedDict\n\nclassifier = nn.Sequential(OrderedDict([\n    ('linear1', nn.Linear(model.fc.in_features, 256)),\n    ('relu1', nn.ReLU()),\n    ('drop', nn.Dropout(0.2)),\n    ('linear2', nn.Linear(256, 2)),\n    ('output', nn.LogSoftmax(dim=1))\n]))\n    \nmodel.fc = classifier","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:59:24.461505Z","iopub.execute_input":"2022-06-13T12:59:24.461956Z","iopub.status.idle":"2022-06-13T12:59:24.479613Z","shell.execute_reply.started":"2022-06-13T12:59:24.461923Z","shell.execute_reply":"2022-06-13T12:59:24.478347Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. The linear algebra computations are done in parallel on the GPU leading to 100x increased training speeds. It's also possible to train on multiple GPUs, further decreasing training time.\n\nPyTorch, along with pretty much every other deep learning framework, uses [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch, you move your model parameters and other tensors to the GPU memory using `model.to('cuda')`. You can move them back from the GPU with `model.to('cpu')` which you'll commonly do when you need to operate on the network output outside of PyTorch. As a demonstration of the increased speed, I'll compare how long it takes to perform a forward and backward pass with and without a GPU.","metadata":{}},{"cell_type":"markdown","source":"We can check if the GPU is available with \n\n`torch.cuda.is_available()` .\n\nThis command can be used to make a model that is agnostic to the device we are using, simply defining:\n\n`device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")`\n\nin this way, device will be \"cuda:0\" if a GPU is available, or \"cpu\" if it is not!\n\n","metadata":{}},{"cell_type":"markdown","source":"So, whenever you get a new Tensor or Module:\n\n```python\ninput = data.to(device)\nmodel = MyModule(...).to(device)\n```\n\nThis tells the machine to move the data or the model on the GPU if available, so that you can speed up a lot your training process! If the data are already on cpu/gpu and you are running the lines above, nothing will happen! \n","metadata":{}},{"cell_type":"code","source":"# # Use GPU if it's available\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# model = models.densenet121(pretrained=True)\n\n# # Freeze parameters so we don't backprop through them\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# # Change the classifier to make it work with your binary classification problem\n\n# model.classifier = nn.Sequential(# your code here)\n\n# criterion = nn.NLLLoss()\n\n# # Only train the classifier parameters, feature parameters are frozen\n# optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n\n# model.to(device);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">**Exercise** Complete the code below to complete the training and the validation.","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel.to(device)\nlearning_rate = 0.001\nepochs = 10\n\noptimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\ncriterion = nn.NLLLoss()\n\ntrain_losses = []\ntest_losses = []\ntrain_accuracies = []\ntest_accuracies = []\nbenchmark_accuracy = 0.90\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n    running_accuracy = 0\n    running_loss = 0\n    # training\n    for x_train_batch, y_train_batch in trainloader:\n        x_train_batch = x_train_batch.to(device)\n        y_train_batch = y_train_batch.to(device)\n\n        optimizer.zero_grad()\n\n        # forward pass\n        logits = model(x_train_batch)\n        train_preds = torch.argmax(logits.detach(), dim=1)\n\n        # loss\n        train_loss = criterion(logits, y_train_batch)\n        running_loss += train_loss.item()\n\n        # train accuracy\n        train_acc = (y_train_batch == train_preds).sum() / len(y_train_batch)\n        running_accuracy += train_acc.item()\n\n        # backward pass\n\n        train_loss.backward()\n\n        # update paramaters\n\n        optimizer.step()\n\n    # mean loss (all batches losses divided by the total number of batches)\n    train_losses.append(running_loss / len(trainloader))\n\n    # mean accuracies\n    train_accuracies.append(running_accuracy / len(trainloader))\n\n    # print\n    print(f'Train loss: {train_losses[-1] :.4f}')\n\n    # validation\n    model.eval()\n    with torch.no_grad():\n        running_accuracy = 0\n        running_loss = 0\n\n        for x_test_batch, y_test_batch in testloader:\n            x_test_batch = x_test_batch.to(device)\n            y_test_batch = y_test_batch.to(device)\n            # logits\n            test_logits = model(\n                x_test_batch)\n\n            # predictions\n            test_preds = torch.argmax(test_logits, dim=1)\n\n            # accuracy\n            test_acc = (y_test_batch == test_preds).sum() / len(y_test_batch)\n            running_accuracy += test_acc.item()\n\n            # loss\n            test_loss = criterion(test_logits, y_test_batch)\n            running_loss += test_loss.item()\n\n        # mean accuracy for each epoch\n        test_accuracies.append(running_accuracy / len(testloader))\n\n        # mean loss for each epoch\n        test_losses.append(running_accuracy / len(testloader))\n        # print\n        print(f'Test accuracy: {test_accuracies[-1]*100 :.2f}%')\n        print('='*100)\n        # saving best model\n        # is current mean score (mean per epoch) greater than or equal to the benchmark?\n        if test_accuracies[-1] > benchmark_accuracy:\n            # save model to cpu\n            torch.save(model.to('cpu').state_dict(), './model.pth')\n            model.to(device)  # bring back to gpu\n\n            # update benckmark\n            benchmark_accuracy = test_accuracies[-1]\n\n    model.train()\n\n\n# Plots\nx_epochs = list(range(epochs))\nplt.figure(figsize=(15, 6))\nplt.subplot(1, 2, 1)\nplt.plot(x_epochs, train_losses, marker='o', label='train')\nplt.plot(x_epochs, test_losses, marker='o', label='test')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(x_epochs, train_accuracies, marker='o', label='train')\nplt.plot(x_epochs, test_accuracies, marker='o', label='test')\nplt.axhline(benchmark_accuracy, c='grey', ls='--',\n            label=f'Best_accuracy({benchmark_accuracy*100 :.2f}%)')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig('./learning_curve.png', dpi=200)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:59:54.333540Z","iopub.execute_input":"2022-06-13T12:59:54.334011Z","iopub.status.idle":"2022-06-13T13:31:42.798747Z","shell.execute_reply.started":"2022-06-13T12:59:54.333978Z","shell.execute_reply":"2022-06-13T13:31:42.797610Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.to(device)\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n\nepochs = 1\nsteps = 0\nrunning_loss = 0\nprint_every = 5\nfor epoch in range(epochs):\n    for inputs, labels in trainloader:\n        optimizer.zero_grad()\n        steps += 1\n        # Move input and label tensors to the default device\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # write the training loop. call the loss \"loss\" so that the line below will work\n        logsoft_outs = model.forward(inputs)\n        loss = criterion(logsoft_outs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n\n        \n        \n        if steps % print_every == 0:\n            test_loss = 0 \n            accuracy = 0\n            # REMEMBER TO ACTIVATE THE EVAL MODE\n            model.eval()\n            with torch.no_grad():\n                for inputs, labels in testloader:\n                    inputs, labels = inputs.to(device), labels.to(device)\n                    \n                    logps = model.forward(inputs)\n                    batch_loss = criterion(logps, labels)\n                    \n                    test_loss += batch_loss.item()\n                    \n                    # Calculate accuracy\n                    preds = torch.argmax(logps, dim=1)\n                    accuracy = (preds == labels).sum().item()\n                   \n            print(f\"Epoch {epoch+1}/{epochs}.. \"\n                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n            running_loss = 0\n            # REMEMBER TO REACTIVATE THE TRAIN MODE","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In less than one epoch! ðŸ˜³ðŸ¤© (I manually interrupted the training, this is why there's the error.)\n\nOk, now that you have a great model, it's worth it to save it for use it again later.","metadata":{}},{"cell_type":"code","source":"print(\"Our model: \\n\\n\", model, '\\n')\nprint(\"The state dict keys: \\n\\n\", model.state_dict().keys())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The simplest thing to do is simply save the state dict with `torch.save`. For example, we can save it to a file `'checkpoint.pth'`.","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'checkpoint.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then we can load the state dict with `torch.load`.","metadata":{}},{"cell_type":"code","source":"state_dict = torch.load('checkpoint.pth')\nprint(state_dict.keys())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And to load the state dict in to the network, you do `model.load_state_dict(state_dict)`.\n","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(state_dict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Oh, but what does it mean? \n\nFirst, that you need to have your model defined as the one that has been saved. In other words, if you save the `checkpoint.pth` and send it to your friend, your friend won't be able to use the model *unless* you tell her/him how the model has been defined, which layers it has, how they are called and so on.\n\nIs it useless then? No, on the contrary! Think that you're training a model, with 1000 epochs. It could take three days to do it. What if at the 999th epoch your *Airbnb host* shutdown the wi-fi connection? All your progress are lost! However, since your notebook have all the model defined, you can save the checkpoints every $n$ iterations or *when the validation accuracy improves*.\n\nThis is indeed a common practice: everytime you test your model on the validation set, you can check if the validation accuracy is higher then the one that you have saved already and save the new checkpoints! I recommend to check this out: https://wandb.ai/site\n\nWhat if you try loading the checkpoints with a model that doesn't match?\n","metadata":{}},{"cell_type":"code","source":"# Try this\nimport fc_model\nmodel = fc_model.Network(784, 10, [400, 200, 100])\n# This will throw an error because the tensor sizes are wrong!\nmodel.load_state_dict(state_dict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It was intended to get an error, don't worry. I know that is always scary to see the red message, and your debug mode has already been triggered, but put it aside.\n\n>**Exercise**: Save the checkpoints of your model after 5 epochs of training. Load them back and continue the training for how many epochs you want.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}